{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29052f83-f727-4c0e-bbf9-db0e6ef68adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, max ,avg, min\n",
    "from pyspark.sql.functions import count, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62820658-5c82-4082-b654-dbb060b87d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiffre d'affaires total : 2710 \n",
      "Produit le plus vendu : Souris (10 unités)\n"
     ]
    }
   ],
   "source": [
    "#exo1\n",
    "spark = SparkSession.builder.appName(\"Analyse des ventes\").getOrCreate()\n",
    "#1.\tChargez le fichier CSV dans PySpark.\n",
    "data_path = \"ventes.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "#2.\tCalculez le chiffre d’affaires (Quantité × Prix_unitaire) pour chaque ligne.\n",
    "df = df.withColumn(\"CA\", col(\"Quantité\") * col(\"Prix_unitaire\"))\n",
    "\n",
    "#3.\tCalculez le chiffre d’affaires total.\n",
    "Total_CA = df.agg(sum(\"CA\").alias(\"Total_CA\")).collect()[0][\"Total_CA\"]\n",
    "\n",
    "#4.\tTrouvez le produit le plus vendu\n",
    "produit_plus_vendu = (\n",
    "    df.groupBy(\"Produit\")\n",
    "    .agg(sum(\"Quantité\").alias(\"Total_Quantité\"))\n",
    "    .orderBy(col(\"Total_Quantité\").desc())\n",
    "    .first()\n",
    ")\n",
    "\n",
    "spark.stop()\n",
    "\n",
    "print(f\"Chiffre d'affaires total : {Total_CA} \")\n",
    "print(f\"Produit le plus vendu : {produit_plus_vendu['Produit']} ({produit_plus_vendu['Total_Quantité']} unités)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58ba19cf-ecc5-4b66-88a2-cf3b69baea13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age moyen des utilisateurs : 30.40 ans\n",
      "Nombre d'utilisateurs par ville :\n",
      " - Marseille: 1 \n",
      " - Paris: 2 \n",
      " - Lyon: 2 \n",
      "Le plus jeune utilisateur est Emma avec 22 ans\n"
     ]
    }
   ],
   "source": [
    "#exo2\n",
    "spark = SparkSession.builder.appName(\"Analyse des utilisateurs\").getOrCreate()\n",
    "\n",
    "#1.\tChargez le fichier JSON dans PySpark.\n",
    "data_path = \"utilisateurs.json\"\n",
    "df = spark.read.option(\"multiline\", \"true\").json(data_path)\n",
    "\n",
    "#2.\tCalculez l’âge moyen des utilisateurs.\n",
    "Age_moyen = df.agg(avg(\"age\").alias(\"Age_moyen\")).collect()[0][\"Age_moyen\"]\n",
    "\n",
    "#3.\tComptez combien d’utilisateurs habitent dans chaque ville.\n",
    "utilisateurs_par_ville = df.groupBy(\"ville\").agg(count(\"id\").alias(\"Nombre_utilisateurs\"))\n",
    "\n",
    "#4.\tTrouvez le plus jeune utilisateur.\n",
    "plus_jeune = df.orderBy(col(\"age\").asc()).first()\n",
    "\n",
    "\n",
    "print(f\"age moyen des utilisateurs : {Age_moyen:.2f} ans\")\n",
    "print(\"Nombre d'utilisateurs par ville :\")\n",
    "for row in utilisateurs_par_ville.collect():\n",
    "    print(f\" - {row['ville']}: {row['Nombre_utilisateurs']} \")\n",
    "print(f\"Le plus jeune utilisateur est {plus_jeune['nom']} avec {plus_jeune['age']} ans\")\n",
    "\n",
    "spark.stop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77ac8a34-31d4-49d3-83d9-1f14edfbb675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+------+\n",
      "|   Nom| Âge|    Ville|Revenu|\n",
      "+------+----+---------+------+\n",
      "| Alice|25.0|    Paris| 50000|\n",
      "|   Bob|30.5|     Lyon| 40000|\n",
      "|Claire|35.0|Marseille| 35000|\n",
      "| David|40.0| Inconnue| 45000|\n",
      "+------+----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#exo3\n",
    "spark = SparkSession.builder.appName(\"Nettoyage de données\").getOrCreate()\n",
    "\n",
    "#1.\tChargez le fichier CSV dans PySpark.\n",
    "data_path = \"clients.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "#2.\tRemplissez les valeurs manquantes pour l’âge avec la moyenne des âges.\n",
    "moyenne_age = df.filter(df[\"Âge\"].isNotNull()).agg(avg(\"Âge\")).collect()[0][0]\n",
    "df = df.withColumn(\"Âge\", when(col(\"Âge\").isNull(), moyenne_age).otherwise(col(\"Âge\")))\n",
    "\n",
    "#3.\tRemplissez les valeurs manquantes pour la ville avec “Inconnue”.\n",
    "df = df.withColumn(\"Ville\", when(col(\"Ville\").isNull(), \"Inconnue\").otherwise(col(\"Ville\")))\n",
    "\n",
    "#4.\tSupprimez les lignes où le revenu est manquant.\n",
    "df = df.filter(col(\"Revenu\").isNotNull())\n",
    "\n",
    "#5.\tAffichez le DataFrame nettoyé.\n",
    "df.show()\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17040596-048c-462d-9560-a62897e9c38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----+\n",
      "|   Produit|   Catégorie|Prix|\n",
      "+----------+------------+----+\n",
      "|Ordinateur|Électronique| 800|\n",
      "|     Table|      Bureau| 150|\n",
      "|Imprimante|Électronique| 120|\n",
      "+----------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#exo4\n",
    "spark = SparkSession.builder.appName(\"Analyse des transactions\").getOrCreate()\n",
    "\n",
    "#1.\tChargez le fichier CSV dans PySpark.\n",
    "data_path = \"produits.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "#2.\tIdentifiez les 3 produits les plus chers.\n",
    "df_trie = df.orderBy(df[\"Prix\"].desc()).limit(3)\n",
    "\n",
    "#3.\tAffichez le résultat sous forme de DataFrame.\n",
    "df_trie.show()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ea10ffa-1c1b-42b7-b9f1-e19e8455ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+\n",
      "|Client|Dépenses_totales|\n",
      "+------+----------------+\n",
      "|  Emma|             350|\n",
      "| Alice|             250|\n",
      "| David|             250|\n",
      "|   Bob|             200|\n",
      "+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#exo5\n",
    "spark = SparkSession.builder.appName(\"Analyse des transactions\").getOrCreate()\n",
    "\n",
    "#1.\tChargez le fichier CSV dans PySpark.\n",
    "data_path = \"transactions.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "#2.\tCalculez les dépenses totales de chaque client.\n",
    "df_depenses = df.groupBy(\"Client\").agg(sum(\"Montant\").alias(\"Dépenses_totales\"))\n",
    "\n",
    "#3.\tIdentifiez le client ayant dépensé le plus.\n",
    "df_depenses = df_depenses.orderBy(col(\"Dépenses_totales\").desc())\n",
    "\n",
    "df_depenses.show()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "feb8158d-8f93-4a0b-b498-73a1174f840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+\n",
      "|   Catégorie|Prix_moyen|Prix_total|\n",
      "+------------+----------+----------+\n",
      "|Électronique|    238.75|       955|\n",
      "|      Bureau|     115.0|       230|\n",
      "+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#exo5\n",
    "spark = SparkSession.builder.appName(\"Agrégation de données par catégorie\").getOrCreate()\n",
    "\n",
    "#1.\tChargez le fichier CSV dans PySpark.\n",
    "data_path = \"produits.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "#2.\tCalculez le prix moyen et le prix total par catégorie.\n",
    "df = df.groupBy(\"Catégorie\").agg(\n",
    "    avg(\"Prix\").alias(\"Prix_moyen\"),\n",
    "    sum(\"Prix\").alias(\"Prix_total\")\n",
    ")\n",
    "#3.\tAffichez les résultats dans un DataFrame.\n",
    "df.show()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73f03e-ba23-40d7-a40b-7c3dc0565458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
